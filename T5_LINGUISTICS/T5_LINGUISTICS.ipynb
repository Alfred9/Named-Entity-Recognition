{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6thko93yjcTeI7t6cimND",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alfred9/Natural-Language-Processing/blob/main/T5_LINGUISTICS/T5_LINGUISTICS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bxaI03yp1bUM"
      },
      "outputs": [],
      "source": [
        "!pip install -q pyspark spark-nlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import sparknlp\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from pyspark.sql.types import StringType, IntegerType"
      ],
      "metadata": {
        "id": "pbY0I44f9in9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()\n",
        "\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "w36ZyPqi94Eb",
        "outputId": "2f73b53b-1411-4963-bfc9-8ba7ac158545"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7b6e7d0ca800>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6e87a1902ecb:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documentAssembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"documents\")\n",
        "\n",
        "t5 = T5Transformer.pretrained(\"t5_grammar_error_corrector\") \\\n",
        "    .setTask(\"gec:\") \\\n",
        "    .setInputCols([\"documents\"])\\\n",
        "    .setMaxOutputLength(200)\\\n",
        "    .setOutputCol(\"corrections\")\n",
        "\n",
        "pipeline = Pipeline().setStages([documentAssembler,\n",
        "                                 t5])\n"
      ],
      "metadata": {
        "id": "4_qjVI6U-ZpN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab862864-c899-47b3-a43e-aeebfd8831de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t5_grammar_error_corrector download started this may take some time.\n",
            "Approximate size to download 883.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_model = pipeline.fit(spark.createDataFrame([['']]).toDF('text'))\n",
        "T5model = LightPipeline(pipeline_model)\n",
        "\n",
        "example_txt = \"\"\"\n",
        "\n",
        "Anna and Mike is going skiing and they is liked is\n",
        "\"\"\"\n",
        "\n",
        "res = T5model.fullAnnotate(example_txt)[0]\n",
        "\n",
        "\n",
        "print ('Prediction:', res['corrections'][0].result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ine-k0VVNp-o",
        "outputId": "d26fdf0a-b7c8-49bb-f70d-caa0dd542bf0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Anna and Mike are going skiing and they like it.\n"
          ]
        }
      ]
    }
  ]
}